---
course: CS M146
area: ucla
created: 2023-04-03T14:42
updated: 2023-05-08T00:22
ðŸ“• courses:
  - "[[CS M146- Machine Learning]]"
---
# Definitions

---

# Big Ideas

---

## Types of Learning

### Supervised

- used for prediction
- given a labeled training set â†’ learn a pattern/mapping for test set
- Regression â†’ labels are continuous
- Classification â†’ labels are discrete
- uses features/attributes to train on: tumor size, age, etc.

### Unsupervised

- for detecting patterns
- given unlabeled data â†’ find patterns (intrinsic structure)

### Reinforcement

- used to interact in an environment
- not input data, just the environment â†’ trial-and-error
- usually given a utility function (goal) â†’ rewards the model for correct interactions

## Machine Learning Goal

Given:

- a training dataset consists of $n$ï»¿ labelled training instances for each has
- input features/attributes: $\vec X = [\vec x^{(1)},â€¦,\vec x^{(n)}]$ï»¿ where $x^{(i)}\in \R^d$ï»¿ for $d$ï»¿ features
- labels $\vec y=[y^{(1)},â€¦,y^{(n)}]$ï»¿ where $y^{(i)}\in\R$ï»¿ or f we know limits (e.g. price >0) $\R^+$ï»¿

Output:

- hypothesis function: $h:\R^d\to\R$ï»¿ from a hypothesis class (a family of functions e.g. for linear regression all linear functions) $h\in \mathcal H$ï»¿ s.t. $h(\vec x)\approx y$ï»¿

  

Steps for learning $h$ï»¿:

1. Represent (find) hypothesis class $\mathcal H$ï»¿
2. Define a loss (function)
3. Optimize for the best $h\in \mathcal H$ï»¿ s.t. $h(\vec x)\approx y$ï»¿

# Resources

---

[](https://www.notion.soundefined)

ðŸ“Œ

**SUMMARY  
**